{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages and Trained Model from Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import cv2\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "# tensorflow & keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Activation, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# additional packages for working with directories\n",
    "from PIL import Image\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.8.0\n",
      "GPU Check: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# check version and ensure gpu is detected\n",
    "print(f\"TensorFlow Version: {tf.version.VERSION}\")\n",
    "print(f\"GPU Check: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('final_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Object Detection Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the classifications\n",
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'delete', 'space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = './data_my_images/2022-02-16 13_37_10-Camera.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = tf.keras.preprocessing.image.load_img(test_img_path, target_size=(64,64))\n",
    "\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(test_img)\n",
    "input_arr = np.array([input_arr])\n",
    "input_arr = input_arr.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(input_arr)\n",
    "predicted_class = np.argmax(predictions, axis=-1)\n",
    "#predicted_class_name = classes[predicted_class[0]]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2698acaf370>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.predict(input_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Object Detection with Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 10\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "fps = int(cap.get(5))\n",
    "print(\"fps:\", fps)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "    num_detections = int(detections)\n",
    "\n",
    "\n",
    "\n",
    "    detections = detect_fn(input_tensor)\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bounding box for gesture input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream bounding box images as model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply model estimation and confidence to bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee13212e048351a7fdc24cbb51d496998848c3bf3f921eee2ef591e22e544036"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('MRI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
